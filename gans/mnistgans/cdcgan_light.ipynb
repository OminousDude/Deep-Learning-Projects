{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.image = nn.Sequential(\n",
    "            nn.ConvTranspose2d(100, 64 * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.label = nn.Sequential(\n",
    "            nn.ConvTranspose2d(10, 64 * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64 * 8, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64*2, 64, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        image = self.image(image)\n",
    "        label = self.label(label)\n",
    "        incat = torch.cat((image, label), dim=1)\n",
    "        return self.main(incat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.image = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.label = nn.Sequential(\n",
    "            nn.Conv2d(10, 64, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(64 * 2, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 4, 64 * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64 * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64 * 8, 1, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        image = self.image(image)\n",
    "        label = self.label(label)\n",
    "        incat = torch.cat((image, label), dim=1)\n",
    "        return self.main(incat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CGAN(pl.LightningModule):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.generator = Generator()\n",
    "\t\tself.discriminator = Discriminator()\n",
    "\n",
    "\t\tself.automatic_optimization = False\n",
    "\n",
    "\tdef forward(self, z, y):\n",
    "\t\treturn self.generator(z, y)\n",
    "\n",
    "\tdef generator_step(self, x):\n",
    "\t\tz = torch.randn(x.shape[0], 100, 1, 1).to(\"cuda\")\n",
    "\n",
    "\t\ty = torch.randint(0, 10, size=(x.shape[0], 100, 1, 1), device=\"cuda\")\n",
    "\n",
    "\t\tgenerated_imgs = self(z, y)\n",
    "\n",
    "\t\td_output = torch.squeeze(self.discriminator(generated_imgs, y))\n",
    "\n",
    "\t\tg_loss = nn.BCELoss()(d_output,\n",
    "\t\t\t\t\t\t\ttorch.ones(x.shape[0], 100, 1, 1).to(\"cuda\"))\n",
    "\n",
    "\t\treturn g_loss\n",
    "\n",
    "\tdef discriminator_step(self, x, y):\n",
    "\t\td_output = torch.squeeze(self.discriminator(x, y))\n",
    "\t\tloss_real = nn.BCELoss()(d_output,\n",
    "\t\t\t\t\t\t\t\ttorch.ones(x.shape[0], 100, 1, 1).to(\"cuda\"))\n",
    "\n",
    "\t\tz = torch.randn(x.shape[0], 100, 1, 1).to(\"cuda\")\n",
    "\t\ty = torch.randint(0, 10, size=(x.shape[0], 100, 1, 1), device=\"cuda\")\n",
    "\n",
    "\t\tgenerated_imgs = self(z, y)\n",
    "\t\td_output = torch.squeeze(self.discriminator(generated_imgs, y))\n",
    "\t\tloss_fake = nn.BCELoss()(d_output,\n",
    "\t\t\t\t\t\t\t\ttorch.zeros(x.shape[0], 100, 1, 1).to(\"cuda\"))\n",
    "\n",
    "\t\treturn loss_real + loss_fake\n",
    "\n",
    "\tdef training_step(self, batch, batch_idx):\n",
    "\t\tX, y = batch\n",
    "\n",
    "\t\tg_optimizer, d_optimizer = self.optimizers()\n",
    "\n",
    "\t\tg_loss = self.generator_step(X)\n",
    "\t\t\n",
    "\t\td_loss = self.discriminator_step(X, y)\n",
    "\n",
    "\t\treturn g_loss - d_loss\n",
    "\n",
    "\tdef configure_optimizers(self):\n",
    "\t\tg_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.0002)\n",
    "\t\td_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)\n",
    "\t\treturn [g_optimizer, d_optimizer], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "real_label_num = 1.\n",
    "fake_label_num = 0.\n",
    "\n",
    "label_1hots = torch.zeros(10,10)\n",
    "for i in range(10):\n",
    "    label_1hots[i,i] = 1\n",
    "label_1hots = label_1hots.view(10,10,1,1).to(\"cuda\")\n",
    "\n",
    "label_fills = torch.zeros(10, 10, 28, 28)\n",
    "ones = torch.ones(28, 28)\n",
    "for i in range(10):\n",
    "    label_fills[i][i] = ones\n",
    "label_fills = label_fills.to(\"cuda\")\n",
    "\n",
    "fixed_noise = torch.randn(100, 100, 1, 1).to(\"cuda\")\n",
    "fixed_label = label_1hots[torch.arange(10).repeat(10).sort().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | generator     | Generator     | 3.2 M \n",
      "1 | discriminator | Discriminator | 2.6 M \n",
      "------------------------------------------------\n",
      "5.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.8 M     Total params\n",
      "23.389    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c983541c594af4a9ffa4bb1b61c41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given transposed=1, weight of size [10, 256, 4, 4], expected input[128, 100, 1, 1] to have 10 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model \u001b[39m=\u001b[39m CGAN()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, accelerator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m, devices\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(model, mnist_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:545\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TrainerStatus\u001b[39m.\u001b[39mRUNNING\n\u001b[1;32m    544\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 545\u001b[0m call\u001b[39m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    546\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    547\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mif\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     46\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:581\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    576\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    577\u001b[0m     ckpt_path,\n\u001b[1;32m    578\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    580\u001b[0m )\n\u001b[0;32m--> 581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run(model, ckpt_path\u001b[39m=\u001b[39mckpt_path)\n\u001b[1;32m    583\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    584\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:990\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signal_connector\u001b[39m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    987\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[39m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 990\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_stage()\n\u001b[1;32m    992\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    994\u001b[0m \u001b[39m# ----------------------------\u001b[39;00m\n\u001b[1;32m    995\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py:1036\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1035\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1036\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mrun()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnexpected state \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:202\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance()\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    204\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:359\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    358\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_loop\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:136\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    135\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(data_fetcher)\n\u001b[1;32m    137\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end(data_fetcher)\n\u001b[1;32m    138\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/training_epoch_loop.py:242\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    240\u001b[0m             batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautomatic_optimization\u001b[39m.\u001b[39mrun(trainer\u001b[39m.\u001b[39moptimizers[\u001b[39m0\u001b[39m], batch_idx, kwargs)\n\u001b[1;32m    241\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m             batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanual_optimization\u001b[39m.\u001b[39mrun(kwargs)\n\u001b[1;32m    244\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    246\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/manual.py:92\u001b[0m, in \u001b[0;36m_ManualOptimization.run\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_run_start()\n\u001b[1;32m     91\u001b[0m \u001b[39mwith\u001b[39;00m suppress(\u001b[39mStopIteration\u001b[39;00m):  \u001b[39m# no loop to break at this level\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madvance(kwargs)\n\u001b[1;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_run_end()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loops/optimization/manual.py:112\u001b[0m, in \u001b[0;36m_ManualOptimization.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m trainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\n\u001b[1;32m    111\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m training_step_output \u001b[39m=\u001b[39m call\u001b[39m.\u001b[39m_call_strategy_hook(trainer, \u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39mkwargs\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m    113\u001b[0m \u001b[39mdel\u001b[39;00m kwargs  \u001b[39m# release the batch from memory\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()  \u001b[39m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py:309\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m trainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 309\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py:382\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module:\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_redirection(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39m\"\u001b[39m\u001b[39mtraining_step\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 382\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module\u001b[39m.\u001b[39mtraining_step(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32m/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m X, y \u001b[39m=\u001b[39m batch\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m g_optimizer, d_optimizer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizers()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m g_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator_step(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m d_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator_step(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mreturn\u001b[39;00m g_loss \u001b[39m-\u001b[39m d_loss\n",
      "\u001b[1;32m/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m, size\u001b[39m=\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m), device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m generated_imgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(z, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m d_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqueeze(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator(generated_imgs, y))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m g_loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()(d_output,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \t\t\t\t\ttorch\u001b[39m.\u001b[39mones(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, z, y):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerator(z, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, image, label):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage(image)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel(label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     incat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((image, label), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/maxim/Documents/TestProject/gans/cdcgan_light.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain(incat)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:952\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    947\u001b[0m num_spatial_dims \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    948\u001b[0m output_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_padding(\n\u001b[1;32m    949\u001b[0m     \u001b[39minput\u001b[39m, output_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    950\u001b[0m     num_spatial_dims, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv_transpose2d(\n\u001b[1;32m    953\u001b[0m     \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding,\n\u001b[1;32m    954\u001b[0m     output_padding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given transposed=1, weight of size [10, 256, 4, 4], expected input[128, 100, 1, 1] to have 10 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "mnist_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "                                    transforms.Lambda(lambda x: x.view(-1, 784)),\n",
    "                                    transforms.Lambda(lambda x: torch.squeeze(x))\n",
    "                                    ])\n",
    "\n",
    "data = datasets.MNIST(root='../data/MNIST', download=True, transform=mnist_transforms)\n",
    "\n",
    "mnist_dataloader = DataLoader(data, batch_size=128, shuffle=True, num_workers=20) \n",
    "\n",
    "model = CGAN()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1)\n",
    "trainer.fit(model, mnist_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-990273a5072df791\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-990273a5072df791\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
